---
title: 'Unsupervised Learning in Calorimetry Waveform Analysis'
date: 2018-10-20
permalink: /posts/2018/research-post-1/
tags:
  - research
  - machine learning
---
The waveforms
====
For this study of mine, I am going to focus on the efforts of classifying different shape of waveform using VAE comparing with simple reconstructed parameters in a neutrinoless double beta experiment. This studies is motivated by my interest of how machine learning can be incorporate into typical physics analysis flow and how such technique can improve analysis process and alternative methods of interpreting experimental data. The goal of this studies is to show the possibility how can such technique can be applied to search unexpected signal in a background heavy dataset.

Classifying signal from raw detector level data
====
Classification task in experimental physics are more commonly known as event selection in physics literatures. Physicist reconstructs physical variables from the raw data by detectors based on the expected physical characteristic of the signal wanted from our physics knowledge. From these reconstructed variables, physicist select signal-like events by eliminating background that are beyond the expected range of the signal desired. This is an over-simplify explanation but this is the gist of how event selection are carried out in physics experiment.

Unsupervised learning and VAE
====
There are plenty of example of how supervised learning is used for classification task in wide area of physics experiment. Ranging from identifying jet events at LHC(cite!) to gravitational wave classification(cite!). Most of classification ask in physics that uses machine learning technique are simply an application of machine learning algorithms in physics. The most commonly applied technique derived from a branch of machine learning known as supervised learning where labeled dataset are used to train an algorithm and using the trained algorithm to identify the labels of a different dataset. In physics, simulated data are used to train the algorithm and then using the trained algorithm to classify actual experimental dataset. In some cases, machine learning techniques can improve the separation ability of conventional used technique in physics. I myself am intrigued by the recent development of machine learning in physics where unsupervised learning is still yet produce meaningful result in the area of physics. In this studies of mine, I am going to test how can we classify different physics event without specifically engineer the algorithm and achieved comparable result with conventional methods. To take a step further, to show that the possibility to uncover hidden glitches or entirely new physics events from actual experimental dataset.

Unsupervised learning does not required labeled dataset to train the neural network but itself try to learn the hidden data structure of the dataset. A type of neural network used in unsupervised learning, auto-encoder is a type of neural network where it tries to reproduced the initial input where a large input information is condense into smaller latent variables where from these latent variables it tries to recreate the input information. This compressing of information by an auto-encoder is akin to what physicist normally does where variables are reconstructed from the raw data as these variables described the basic physical properties of each event that is understood by physicist. In the case of an auto-encoder, it learns how to derived latent variables by itself albeit difficult to be understood by a human.

For this study, instead focusing on the standard auto-encoder, the way variational auto-encoder(VAE) compressed multi-dimensional data into smaller latent variable. Generically, any auto-encoder would work but this time I used this opportunity of understand the potential of VAEs.

To train the VAE, an actual raw waveform dataset which comprises a multitude of different shape of waveform was used. To make the VAE even more robust, additional dataset were made from the original dataset by flipping backwards(np.flip), shifting the start of the pulse randomly(np.roll) and random noise sample(np.shuffle). The purpose of the extra dataset so that the VAE is capable to reproduce any kind of pulse shape/waveform and making sure every node in the VAE is thoroughly trained. Originally I only trained the VAE using the raw waveform only but discover that the VAE could only reproduce the the early part of the pulse closely but not the latter. I later realise because the later part of the pulse/waveform usually are small in value and are almost zero, this mean to train the VAE in the later half of the pulse requires much more time and the nodes in the VAE for these later part are much less trained than the earlier part of the pulse. Thus this is why I artificially added the additional dataset through mathematical operations. The diagram belows shows a sample of the raw waveform that was used to train the VAE.

![train]

To test this idea, I used 2 group of pulses/waveform that represent alpha and beta events, ie: two different type of physics events. The averaged waveform of this 2 group of pulses.

![2group]

The main differences of this 2 groups can be seen in the plot below in the early portion of the waveform.

![2groupzoom]

The 2 plots above is the average waveform where it is used as the expected pulse shape in the $\chi^2$ method. In reality, each idividual waveform are much more noisy.

The alpha pulses

![alpha]

The beta pulses

![beta]

At a glance, One would say there is no significant different upon inspection. To see that difference observed by the averaged waveform, I plot 2 waveform from each alpha and beta pulses.

![samplezoom]

That difference is very subtle(between 100 to 200, there is 2 groups of waveforms with one group has higher initial amplitude) due to the noise that is present in every waveform. As $\chi^2$ is calculated using every point in the waveform

![vis]

The first paramters reconstructed uses $\chi^2$ curve fitting uses the whole waveform and gives ~97.7% cut efficiency

![psd1]

To improve this cut efficiency, the next reconstructed parameter still uses the same $\chi^2$ fitting but only uses the front portion of the waveform as it is known from the averaged waveform between the two , most of the difference can be observed here. This improves the cut efficiency to ~99.3%

![psd7]

However these cut efficiency are obtain using actual dataset where extremely narrow cut condition were used to obtain the ideal events in respectively dataset. In each event, the waveform are noisy where $\chi^2$ method does not mitigate the noise when calculating the $\chi^2$ value. In a sense, this is a "rigid" comparison technique. Irregularities in the surviving dataset can only be observed by inspecting each waveform individually.

Bringing in unsupervised technique, we can train an auto-encoder to reconstruct the experimental data where the AE itself can learn the latent variable of the dataset without any prior information by human. The $\chi^2$ method requires us user to know the characteristic we are looking for therefore may missed out minor features that is yet known to user.

By applying t-SNE algorithm onto the latent variable learned by the VAE, the 2 dataset can be represented as a 2D plot shown here.

![tsne]

We can clearly see it is indeed the dataset has 2 clusters which corresponds to 2 different type of waveforms.

As we have the label of the dataset, we can assign labels to each of the points in the t-SNE plot.

![orilabel]

Here we see that the original dataset in each dataset contain a small subset of the opposite dataset. There is a possibility that the averaged waveform contain some "impurities" where these reconstructed parameters arises from.

To check the reliability of the reconstructed parameters that will be ultimately used to separate the dataset between alpha and beta.

![psdcut]

We can still observed it is not as clean as we thought. If t-SNE reflect the actual clustering of the dataset, then ideally we would like to have a separation as below according to the clustering algorithm.

![result]

The VAE was trained using all events in actual experiments without any prior cuts. Therefore the VAE should have captured every possible features in the experimental dataset.



Visualising the latent variable of VAE through t-SNE
====
t-SNE is a great visualising tools to visualise any multi-dimension dataset into simple 2,3 dimension that can be easily plotted. There is a caveat using t-SNE that this algorithm does not capture the distribution nor the density of dataset thus any clustering seen via t-SNE should be not interpreted as the difference/distance between clustering. Nevertheless it is still a great tool to visualise the dataset we have. Here I will demonstrate how the latent variable and derived variable are clustered via t-SNE.

Methodology - training the VAE
====
The goal of this VAE is to reproduce the waveform that is fed into. Therefore for this study, I used actual raw data from experiment to train the VAE,


Event selection through clustering(t-SNE)
====
Raw data -> reconstructed parameters -> apply cut condition using the reconstructed parameters to select the signal we are interested. ie:- experimental data that have similar properties to the expected signal. 

Comparing with reconstructed parameters (chi-squared curve fitting)
====

Comments
====
Curve fitting is very rigid, A straight up cut-off value w

References:-
====
1. Takaki Ohata, Search for Neutrinoless Double Beta Decay in 48Ca with the CANDLES III experiment, Ph.D thesis Osaka University, 2018
2. L.J.P. van der Maaten and G.E. Hinton, Visualizing High-Dimensional Data Using t-SNE. Journal of Machine Learning Research 9(Nov):2579-2605, 2008. 
3. Danilo J. Rezende, Shakir Mohamed and Daan Wierstra, Stochastic Backpropagation and Approximate Inference in Deep Generative Models, 31st ICML, 2004
4. PyTorch
5. SkLearn

[alpha]: https://raw.githubusercontent.com/hareyakana/hareyakana.github.io/master/images/alpha.png
[beta]: https://raw.githubusercontent.com/hareyakana/hareyakana.github.io/master/images/ref.png
[sample]: https://raw.githubusercontent.com/hareyakana/hareyakana.github.io/master/images/mix.png
[samplezoom]: https://raw.githubusercontent.com/hareyakana/hareyakana.github.io/master/images/zoom.png
[train]: https://raw.githubusercontent.com/hareyakana/hareyakana.github.io/master/images/train.png
[2group]: https://raw.githubusercontent.com/hareyakana/hareyakana.github.io/master/images/2sam.png
[2groupzoom]: https://raw.githubusercontent.com/hareyakana/hareyakana.github.io/master/images/2samfo.png
[psd1]: https://raw.githubusercontent.com/hareyakana/hareyakana.github.io/master/images/psd1.png
[psd7]: https://raw.githubusercontent.com/hareyakana/hareyakana.github.io/master/images/psd7.png
[tsne]: https://raw.githubusercontent.com/hareyakana/hareyakana.github.io/master/images/tsne.png
[orilabel]: https://raw.githubusercontent.com/hareyakana/hareyakana.github.io/master/images/tsneori.png
[psdcut]: https://raw.githubusercontent.com/hareyakana/hareyakana.github.io/master/images/tsnepsd.png
[result]: https://raw.githubusercontent.com/hareyakana/hareyakana.github.io/master/images/desired.png
[vis]: https://raw.githubusercontent.com/hareyakana/hareyakana.github.io/master/images/sketchblog.png
